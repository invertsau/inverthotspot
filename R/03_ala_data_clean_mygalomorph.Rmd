---
title: "Data cleaning"
author: "Ashley Browse"
date: "2023-08-11"
output: rmdformats::downcute
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE)
```


# Cleaning data from ALA

<!-- ## Load dependencies -->

```{r loadpackages, eval=TRUE, echo=FALSE}
# install.packages("pacman")
pacman::p_load(galah, arrow, here, tidyverse, janitor, dplyr, galah, worrms, ozmaps, sf, CoordinateCleaner, maps, job)

source(here("R/utils.R"))

```


<!-- Introduction message, and define variables  -->
```{r, echo=F}
focus_taxon <- "Mygalomorphae spider"
focus_taxon_short <- "Mygal"

```

This document lays out the workflow of cleaning **`r focus_taxon`** data from the ALA database using R.


<!-- ## Read in parquet (observations retrieved from ALA) -->

```{r, eval=TRUE, echo=FALSE}
myg_spiders_all <- open_dataset(here(get_latest_download()))

```

<!-- ## Subset columns we want -->

```{r, eval=TRUE, echo=FALSE}
myg_spiders <- myg_spiders_all |> 
  select(recordID:outlierLayer) |> 
  collect()

unique_species <- unique(myg_spiders$species) |> length()

```

The data includes **`r unique_species`** species of **`r focus_taxon_short`s**, with **`r length(myg_spiders$recordID)`** records in total. Some pre cleaning of the data was done using ALA before downloading, but many of these records may still have errors.

## Taxonomic errors

<!-- Clean for taxonomic errors: misspelt names, incorrect, synonyms.  -->

Here we clean the data for taxonomic errors, such as misspelt and outdated names.

### Filter down to species level data

```{r, echo=FALSE}

count_before_filter <- length(myg_spiders$recordID)
  
myg_species <- myg_spiders |> 
  dplyr::filter(taxonRank == "species")

```

We verified that all records have species level taxonomic data.
There were **`r length(myg_spiders$recordID) - count_before_filter`** records without species level data.

### Read in Australian Faunal Directory (AFD) data to cross check out taxa

The [Australian Faunal Directory (AFD)](https://biodiversity.org.au/afd/home) is an online catalogue of taxonomic and biological information on all animal species known to occur within Australia and its territories.

The AFD can provide information on: 

- nomenclature and taxonomy of species (including current, previous, and synonyms of species names);
- type data information;
- bibliographic information for species;
- distribution of species.

We used AFD data to ensure all species names in the ALA dataset are valid.

<!-- Check names against a naming authority to make sure all species included in the analyses are valid -->

```{r, echo=FALSE}
afd <- open_dataset(here("data/afd_05-2023_clean.parquet"))

# Filter down to Arachnida 
arachnids <- afd |> 
  filter(CLASS == "ARACHNIDA") |> 
  collect()
```

<!-- Where is Mygalomorphae in the AFD? -->
<!-- Filter down to Mygalomorphae using `HIGHER_CLASSIFICATION` -->
 
```{r, eval=FALSE, echo=F}
arachnids |> 
  pull(HIGHER_CLASSIFICATION) |> 
  str_subset(pattern = "MYGALOMORPH")
```

<!-- How many matches of ALA data do we have in the AFD? How many species did not match? Which species don't match? -->

```{r, echo=FALSE}
# how many species in ALA data matched species in the AFD?
AFD_matched <- myg_species |> 
  filter(scientificName %in% arachnids$FULL_NAME) |> 
  pull(scientificName) |> 
  unique() |> 
  length()  # put into sentence form

# How many and which ones are the species in ALA data that DID NOT match with the AFD
AFD_unmatched <- myg_species |> 
  filter(! scientificName %in% arachnids$FULL_NAME) |> 
  pull(scientificName) |> 
  unique() |> 
  length()

# Why are these species not in the AFD? These might be synonyms! 
unmatched_ala_sp <- myg_species |> 
  filter(! scientificName %in% arachnids$FULL_NAME) |> 
  pull(scientificName) |> 
  unique() 

AFD_matched/unique_species *100

```

Of the **`r unique_species`** unique **`r focus_taxon_short`** species in the ALA dataset, **`r AFD_matched`** matched those listed in the AFD (**`r round(AFD_matched/unique_species *100, 2)`** %). These **`r AFD_unmatched`** species did not match:
_**`r unmatched_ala_sp`**_.

<!-- Which of the ALA species not matched to AFD occur in the list of AFD arachnid species synonyms -->

The AFD lists any applicable synonyms for each species within their database. Our **`r AFD_unmatched`** missing species might be synonyms of listed species.

```{r, echo=F}

# Pull out the species name from Synonyms without the Authority
# "Austrammo monteithi Platnick, 2002"     -> "Austrammo monteithi"
# word(), str_split()

# Using similar methods above try cross match unmatched_ala_sp to synonyms

# arachnids$SYNONYMS |> head()
#remove Authority, keep species name
# word(arachnids$SYNONYMS, 1, 2) |> head()

#check if unmatched species occur in list of synonyms
issynonym <- unmatched_ala_sp %in% word(arachnids$SYNONYMS, 1, 2)
```

**`r sum(issynonym)`** unmatched ALA species is an AFD synonym. This is: 
_**`r unmatched_ala_sp[issynonym]`**_.

_**`r unmatched_ala_sp[issynonym]`**_ is a synonym of 
_**`r arachnids[which(word(arachnids$SYNONYMS, 1, 2) == unmatched_ala_sp[issynonym]),18]`**_ 
_**`r arachnids[which(word(arachnids$SYNONYMS, 1, 2) == unmatched_ala_sp[issynonym]),20]`**_.


<!-- Not sure if this is what we want to do, but this is some loose code to replace names found to be synonyms with the new name from the AFD -->
```{r, eval=F, include=F}

# begin a loop for each species flagged as synonyms (just 1 in mygalamorphae)
for (i in 1:length(issynonym)){
  if (issynonym[i]) {
    print(unmatched_ala_sp[i])
  }
}

#get index of species flagged
str_which(myg_species$scientificName, pattern = "armigera")

myg_species[str_which(myg_species$scientificName, pattern = "armigera"),]

#create new scientific name
paste(arachnids[which(word(arachnids$SYNONYMS, 1, 2) == unmatched_ala_sp[issynonym]),18],
      arachnids[which(word(arachnids$SYNONYMS, 1, 2) == unmatched_ala_sp[issynonym]),20])
```


<!-- Excluding introduced/invasives taxa -->

### Use World Spider Catalog and GRIIS to exclude introduced spiders from dataset

The [World Spider Catalogue (WSC)](https://wsc.nmbe.ch/) is a comprehensive online database of spiders from around the world, with detailed taxonomic information, distribution maps, references and images.

```{r, echo=F, include=F}
# Read in spider data downloaded from WSC
wsc <- read_csv(here("data/wsc/species_export_20230929.csv"))
```


<!-- Have a look at distribution variable: How many contain "Australia"? Which ones are "Introduced to Australia"?  -->

```{r, echo=F}
# We want to capture all observations where "Introduced to" and "Australia" occurs together
# Example:
#str_subset(wsc$distribution, pattern = "Introduced to.*Australia")
#str_detect(wsc$distribution, pattern = "Introduced to.*Australia")
#str_which(wsc$distribution, pattern = "Introduced to.*Australia")

introduced_taxa <- wsc |> 
  filter(str_detect(distribution, pattern = "Introduced to.*Australia")) 

# We need to join genus and species together manually
introduced_taxa_wfullname <- introduced_taxa |> 
  mutate(scientific_name = paste(genus, species)) 

# introduced_taxa_wfullname |> 
#   select(scientific_name)

```

WSC lists **`r length(introduced_taxa$speciesId)`** species as introduced to Australia.

<!-- Cross match if introduced taxa from WSC with ALA data to exclude introduced spiders -->

```{r, echo=F, include=F}
introduced_taxa_wfullname$scientific_name %in% myg_species$scientificName |> table()
myg_species$scientificName %in% introduced_taxa_wfullname$scientific_name |> table()
no_Introduced_WSC <- length(which(myg_species$scientificName %in% introduced_taxa_wfullname$scientific_name))
```

There are **`r no_Introduced_WSC`** introduced species of spiders in the ALA data according to the WSC data.


<!-- ### Global Register of Invasive and Introduced Species (GRIIS) -->

The [Global Register of Invasive and Introduced Species (GRIIS)](http://griis.org/) is a project by the IUCN SSC Invasive Species Specialist Group to compile annotated and verified country-wise inventories of introduced and invasive species.

```{r, echo=F, include=F}
# Join distrubtion.txt and taxon-edit.txt
griis_distrib <- read.delim(here("data/griis-australia-v1.6/distribution.txt"))
griis_taxon <- read.delim(here("data/griis-australia-v1.6/taxon-edited.txt"))
# check if both lists are the same length
count(griis_distrib) #length = 2984
count(griis_taxon) #length = 2960
# which IDs are missed? (What is in Distribution that is not in Taxon?)
setdiff(griis_distrib$id, griis_taxon$id) |> length() # 24 missing
# What's in Taxon that is not in Distribution?
setdiff(griis_taxon$id, griis_distrib$id) # none missing

griis_all <- left_join(griis_distrib, griis_taxon, by = "id")  # Apply left_join dplyr function 

# filter by class = arachnida
str_subset(griis_all$class, "Arachnida") # no results
# show unique values to double check there are no arachnids
griis_all$class |> unique() # there are no arachnids in this list

# Cross match with ALA data

# length(str_subset(griis_all$class, "Arachnida"))

```

The GRIIS contains **`r count(griis_all)`** records of introduced species in Australia. 

**`r length(str_subset(griis_all$class, "Arachnida"))`** of these are Arachnids.


<!-- Excluding marines -->

<!-- Notes from Payal -->
<!-- Decide whether to keep morpho-species  -->
<!-- How do you distinguish these in ALA data? -->
<!-- FK to check with PB, I don't think these in are ALA data -->
```{r, echo=F}

```


### Subspecies

<!-- Decide whether to keep sub-species and if not whether to combine their data with the parent species -->
 
```{r, echo=F}
# look for subspecies
# what taxon levels are in the ALA data?
# myg_spiders$taxonRank |> unique() #what is "unranked" and "NA"
# myg_spiders |> filter(taxonRank == "unranked") #no species IDs
# myg_spiders |> filter(taxonRank == "NA") #nothing

# look at unique species
# myg_spiders$species |> unique() #no subspecies here

# check if any species have more than 2 words:
# Function to count words in a string
count_words <- function(string) {
  words <- strsplit(string, "\\s+")[[1]]  # Split the string into words
  return(length(words))                   # Return the number of words
}
word_counts <- lapply(myg_spiders$species |> unique(), count_words)
# which(word_counts != 2) 
```

There are **`r length(which(word_counts != 2))`** subspecies of `r focus_taxon_short`s within the ALA data.

### Excluding Marine Species

WORMS introduction...

Using this function to cross match our species list to the WORMS database

```{r, eval=FALSE, echo=F}
wm_records_taxamatch("Teranodes")
Myg_species <- myg_spiders$species |> unique()




job::job({
  output_df <- map(Myg_species,
                   possibly(~wm_records_taxamatch(.x, marine = FALSE)  |>
                              pluck(1)  |>
                              mutate(search_term = .x) |>
                              discard(.p = ~is.null(.x))
                   )
  ) |>
    list_rbind()

  saveRDS(output_df, "output/worrms_myg_wm_records_taxamatch.rds")
})
```



```{r, echo=FALSE}
#read RDS

wormsOutput <- readRDS(here("output/worrms_myg_wm_records_taxamatch.rds"))
str(wormsOutput)
head(wormsOutput)
wormsOutput$match_type

#%in%
#find exact matches between our ALA data and worms output
length(which(wormsOutput$match_type %in% "exact"))
wormsOutput$match_type %in% "near"
wormsOutput$scientificname
wormsOutput$search_term
wormsOutput |> select(scientificname, search_term, match_type)
names(wormsOutput)

```

There are `r length(which(wormsOutput$match_type %in% "exact"))` matches

### Geographic errors

Here we clean the data for geographic errors, including invalid lat/long, and masking by land/water.

```{r, echo=F}
myg_species_aus <- myg_species |> 
  filter(decimalLatitude != "NA",
         decimalLongitude != "NA") #remove NA coordinates

myg_species_aus <- myg_species_aus |> 
  filter(decimalLatitude != "0",
         decimalLongitude != "0") #remove empty coordinates

#summary(myg_species$decimalLatitude)
#summary(myg_species_aus$decimalLatitude) #347 NA records removed
nrow(myg_species) - nrow(myg_species_aus) # total of 373 records removed
```

There were 

Restricting data to Australia mainland + Tasmania

```{r, echo=F}
myg_species_mainland <- myg_species_aus |> 
  filter(decimalLatitude > -45, 
         decimalLatitude < -8, 
         decimalLongitude > 112, 
         decimalLongitude < 154) 

# Plot:
# Transform into sf object
myg_species_mainland_sf <- myg_species_mainland |> 
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), 
           crs = 4326)

# Verified that we have cropped the data
# Map data
aus <- st_transform(ozmaps::ozmap_country, 4326)

base_map <- ggplot() + 
  geom_sf(data = aus, fill = NA) + 
  theme_minimal()

base_map  + 
  geom_sf(data = myg_species_mainland_sf) + 
  theme_minimal()
```

What are the species we've excluded from the mainland? 

```{r, echo=F}
myg_species_mainland_removed <- anti_join(myg_species_aus, myg_species_mainland)
myg_species_mainland_removed
count(myg_species_mainland_removed)

```

Coordinate Cleaner

https://docs.ropensci.org/CoordinateCleaner/

`.equ` = Equal longitude and latitude
`.sea` = XXX 

```{r, echo=F}
flagged <- clean_coordinates(x = myg_species_mainland, 
                                     "decimalLongitude",
                                     "decimalLatitude")

# Summary of how many flagged records found for each category
summary(flagged)

plot(flagged, lon = "decimalLongitude", lat = "decimalLatitude")
```

### Visualise .sea values

FALSE are values that are flagged to occur in sea and therefore will be eventually excluded


```{r, echo=F}
flagged_sf <- flagged |> 
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), 
           crs = 4326) 

base_map  + 
  geom_sf(data = flagged_sf, aes(color = .sea), alpha = 0.5) +
  theme_minimal()
```

### Visualise .cap values

```{r, echo=F}
flagged_sf <- flagged |> 
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), 
           crs = 4326) 

base_map  + 
  geom_sf(data = flagged_sf, aes(color = .cap), alpha = 0.5) + 
  theme_minimal()
```

### Visualise .otl values

```{r, echo=F}
flagged_sf <- flagged |> 
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), 
           crs = 4326) 

base_map  + 
  geom_sf(data = flagged_sf, aes(color = .otl), alpha = 0.5) + 
  theme_minimal()
```

### Visualise .inst values

```{r, echo=F}
flagged_sf <- flagged |> 
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), 
           crs = 4326) 

base_map  + 
  geom_sf(data = flagged_sf, aes(color = .inst), alpha = 0.5) + 
  theme_minimal()
```

### Exclude records flagged by CoordinateCleaner

```{r, echo=F}

```


## Deduplication
<!-- Check for duplicates (as the last step) -->

In this step we can inspect and clean the data of duplicates 

```{r, echo=F}
nrow(myg_spiders)
head(myg_spiders)

Mygalomorphae_clean <- myg_spiders |> 
  filter(!is.na(decimalLatitude) & !is.na(decimalLongitude)) |>
  filter(!duplicated(decimalLatitude) & !duplicated(decimalLongitude)) 

nrow(Mygalomorphae_clean)
head(Mygalomorphae_clean)
```

## Export cleaned data as a .parquet


<!-- Filename should contain the date of the parquet we read in at the start, export to output folder -->
```{r, echo=F}
get_latest_download()
write_parquet(Mygalomorphae_clean, here(paste0("output/Cleaned_Data_Mygalomorphae_", Sys.Date(), "_ALA.parquet")))
```

